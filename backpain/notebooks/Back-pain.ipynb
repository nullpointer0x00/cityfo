{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from backpain_helper import BackpainHelper\n",
    "from sklearn import datasets, neighbors, metrics,grid_search, model_selection,cross_validation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandas.io import sql\n",
    "import sqlite3\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bh = BackpainHelper()\n",
    "df = bh.get_spine_data()\n",
    "\n",
    "columns = ['pelvic_incidence', 'pelvic_tilt','lumbar_lordosis_angle','sacral_slope','pelvic_radius','degree_spondylolisthesis','pelvic_slope','direct_tilt','thoracic_slope','cervical_tilt','sacrum_angle','scoliosis_slope']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Score from range 1 - 50 of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
      "           weights='distance')\n",
      "0.841935483871\n"
     ]
    }
   ],
   "source": [
    "x = [i for i in range(1, 50)]\n",
    "kf = cross_validation.KFold(len(df), n_folds = 5, shuffle=True)\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=neighbors.KNeighborsClassifier(),\n",
    "    param_grid={'n_neighbors': x, 'weights':['uniform', 'distance']},\n",
    "    cv=kf\n",
    ")\n",
    "gs.fit(df[columns], df.classification)\n",
    "print gs.best_estimator_\n",
    "print gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.tree import export_graphviz\n",
    "# from os import system \n",
    "# def build_tree_image(model):\n",
    "#     dotfile = open(\"tree.dot\", 'w')\n",
    "#     export_graphviz(model,\n",
    "#                               out_file = dotfile,\n",
    "#                               feature_names = columns)\n",
    "#     dotfile.close()\n",
    "#     system(\"dot -Tpng tree.dot -o tree.png\")\n",
    "    \n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "                max_depth = 16,\n",
    "                min_samples_leaf = 5)\n",
    "\n",
    "model.fit(df[columns], df.classification)\n",
    "build_tree_image(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with 5 neighbors and distance as a weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81935483871\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = 20)\n",
    "    \n",
    "model.fit(df[columns], df.classification)\n",
    "\n",
    "kf = cross_validation.KFold(len(df), n_folds = 5, shuffle=True)\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=neighbors.KNeighborsClassifier(),\n",
    "    param_grid={'n_neighbors': [5], 'weights':['distance']},\n",
    "    cv=kf\n",
    ")\n",
    "\n",
    "gs.fit(df[columns], df.classification)\n",
    "# print gs.grid_scores_\n",
    "print gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with logspace -10 -> 10, 21 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: 0.67742, std: 0.07967, params: {'C': 1e-10}, mean: 0.67742, std: 0.07967, params: {'C': 1.0000000000000001e-09}, mean: 0.67742, std: 0.07967, params: {'C': 1e-08}, mean: 0.67742, std: 0.07967, params: {'C': 9.9999999999999995e-08}, mean: 0.67742, std: 0.07967, params: {'C': 9.9999999999999995e-07}, mean: 0.67419, std: 0.08122, params: {'C': 1.0000000000000001e-05}, mean: 0.75484, std: 0.05141, params: {'C': 0.0001}, mean: 0.80645, std: 0.04997, params: {'C': 0.001}, mean: 0.82903, std: 0.04630, params: {'C': 0.01}, mean: 0.83226, std: 0.04630, params: {'C': 0.10000000000000001}, mean: 0.83871, std: 0.04785, params: {'C': 1.0}, mean: 0.83548, std: 0.04719, params: {'C': 10.0}, mean: 0.84516, std: 0.03321, params: {'C': 100.0}, mean: 0.84839, std: 0.03474, params: {'C': 1000.0}, mean: 0.84516, std: 0.03898, params: {'C': 10000.0}, mean: 0.84516, std: 0.03321, params: {'C': 100000.0}, mean: 0.84516, std: 0.03898, params: {'C': 1000000.0}, mean: 0.84516, std: 0.03321, params: {'C': 10000000.0}, mean: 0.84516, std: 0.03321, params: {'C': 100000000.0}, mean: 0.84839, std: 0.03474, params: {'C': 1000000000.0}, mean: 0.84516, std: 0.03898, params: {'C': 10000000000.0}]\n",
      "LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "0.848387096774\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(df[columns], df.classification)\n",
    "\n",
    "alphas = np.logspace(-10,10,21)\n",
    "kf = cross_validation.KFold(len(df), n_folds = 5, shuffle=True)\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid={'C': alphas},\n",
    "    cv=kf\n",
    ")\n",
    "gs.fit(df[columns], df.classification)\n",
    "print gs.grid_scores_\n",
    "print gs.best_estimator_\n",
    "print gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier using nested grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82285048285\n"
     ]
    }
   ],
   "source": [
    "df = bh.get_spine_data()\n",
    "X_data = df[columns]\n",
    "y_data = df.classification\n",
    "model = neighbors.KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': [5], 'weights': ['uniform']}\n",
    "print bh.nested_cross_val(model, X_data, y_data, param_grid, 4, 50).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier using nested grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812977022977\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = 20)\n",
    "param_grid = {}\n",
    "print bh.nested_cross_val(model, X_data, y_data, param_grid, 4, 50).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression using nested grid search and log space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.836576756577\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "alphas = np.logspace(-10,10,21)\n",
    "param_grid = {'C':alphas}\n",
    "print bh.nested_cross_val(model, X_data, y_data, param_grid, 4, 50).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler Logistic Regression Pipeline using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83801032301\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "logistic_model = LogisticRegression()\n",
    "modeling_pipe = Pipeline([('scale',scaler),('model',logistic_model)])\n",
    "modeling_pipe.set_params(model__C = 1)\n",
    "print bh.nested_cross_val(modeling_pipe, X_data, y_data, {}, 4, 50).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator__scale__with_std': True, 'n_jobs': 1, 'verbose': 0, 'estimator__scale': StandardScaler(copy=True, with_mean=True, with_std=True), 'estimator__model__warm_start': False, 'estimator__steps': [('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))], 'param_grid': {}, 'cv': sklearn.cross_validation.KFold(n=310, n_folds=5, shuffle=True, random_state=None), 'scoring': None, 'estimator__model__penalty': 'l2', 'estimator__model__intercept_scaling': 1, 'estimator__model__random_state': None, 'estimator__model__class_weight': None, 'estimator__model__tol': 0.0001, 'fit_params': {}, 'estimator__scale__with_mean': True, 'refit': True, 'estimator__model__solver': 'liblinear', 'estimator__scale__copy': True, 'estimator__model': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), 'estimator__model__verbose': 0, 'pre_dispatch': '2*n_jobs', 'estimator__model__fit_intercept': True, 'iid': True, 'estimator__model__max_iter': 100, 'estimator__model__dual': False, 'estimator': Pipeline(steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))]), 'error_score': 'raise', 'estimator__model__multi_class': 'ovr', 'estimator__model__n_jobs': 1, 'estimator__model__C': 1}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-97e26f0c1c40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfeature_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mfeature_importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mfeatures_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Features'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Importance Score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeature_importances\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "kf = cross_validation.KFold(len(df), n_folds = 5, shuffle=True)\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=modeling_pipe,\n",
    "    param_grid={},\n",
    "    cv=kf\n",
    ")\n",
    "gs.fit(df[columns], df.classification)\n",
    "# print gs.grid_scores_\n",
    "# print gs.best_score_\n",
    "# print gs.best_estimator_\n",
    "\n",
    "print gs.get_params()\n",
    "\n",
    "features = df[columns]\n",
    "feature_importances = np.absolute(gs.best_estimator_.model.coef_)[0]\n",
    "print feature_importances\n",
    "features_df = pd.DataFrame({'Features': columns, 'Importance Score': feature_importances})\n",
    "features_df.sort_values('Importance Score', inplace=True, ascending=False)\n",
    "features_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 7)\n",
      "[-20.58740471 -19.55593929  -1.11701999 -13.92992031  12.60374062\n",
      "  -0.57947982   5.79299672]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = .95, svd_solver = 'full')\n",
    "X_digits_transf = pca.fit_transform(X_train)\n",
    "print X_digits_transf.shape\n",
    "print X_digits_transf[1,:]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
